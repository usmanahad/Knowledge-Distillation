# Knowledge Distillation
An Overview of Different Knowledge Distillation Techniques and their variations:
- Logit Matching (Simple, Decoupled, etc.)
- Feature Matching (FitNets/Hint Losses)
- Contrastive Representation Distillation (CRD)
- Ensembling
